{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils import data\n",
    "def prepare_data():\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "\n",
    "    root_dir = \"./data3/train\";\n",
    "    train_set = datasets.ImageFolder(root = root_dir,\n",
    "                transform = transforms.ToTensor())\n",
    "\n",
    "    trainloader = data.DataLoader(train_set, batch_size = 4, shuffle = True)\n",
    "\n",
    "    root_dir = \"./data3/test\";\n",
    "\n",
    "    train_set = datasets.ImageFolder(root = root_dir,\n",
    "                transform = transforms.ToTensor())\n",
    "\n",
    "    testloader = data.DataLoader(train_set, batch_size =4, shuffle = True)\n",
    "    classes = ('Natalie Portman', 'Julia Roberts', 'Neil Patrick Harris'\n",
    "                    , 'Keifer Sutherland', 'Ben Stiller', 'Anne Hathaway'\n",
    "                    , 'David Boreanaz', 'Jamie Foxx', 'Sofia Vergara'\n",
    "                    , 'Elizabeth Banks', 'Jensen Ackles', 'Amy Adams'\n",
    "                    , 'Kristen Bell', 'Bradley Cooper', 'Emily Deschanel'\n",
    "                    , 'Zooey Deschanel', 'Jon Hamm', 'Scarlett Johansson'\n",
    "                    , 'Blake Lively', 'Eva Longoria', 'Amy Poehler'\n",
    "                    , 'Kristen Stewart', 'Kerry Washington', 'Leighton Meester'\n",
    "                    , 'Olivia Wilde', 'Zac Efron', 'Miley Cyrus','Jim Parsons')\n",
    "    return trainloader, testloader, classes\n",
    "trainloader, testloader, classes = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bellow we have two implementations of neural network - one with two dimentional batch normalization, and the other one \n",
    "without it. Each neural network consists of 4 convolutional layers with filters of sizes(11,9,7,6), with stride 1 and \n",
    "no padding. After each convolutional layer operation MaxPool of size (2,2) is used. Then there are two fully connected \n",
    "layers, first with 3000 input and 600 out, second with 600 input and output of 28."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def tensor_2d_mean(image):\n",
    "    return torch.mm(torch.mm(image,torch.ones(image.shape[0], 1)).T, torch.ones(image.shape[1], 1)) / (image.shape[0]*image.shape[1])\n",
    "\n",
    "def mini_batch_normalization(mini_batch, epsilon):\n",
    "    batch_size = mini_batch.shape[0]\n",
    "    number_of_layers = mini_batch.shape[1]\n",
    "    sum = torch.zeros(mini_batch.shape[2], mini_batch.shape[3])\n",
    "    for i in range(number_of_layers):\n",
    "        for j in range(batch_size):\n",
    "            sum = sum + mini_batch[j][i]\n",
    "        mean = tensor_2d_mean(sum) / batch_size\n",
    "        sum = 0\n",
    "        for j in range(batch_size):\n",
    "            sum += (mini_batch[j][i] - mean)**2\n",
    "        variance = tensor_2d_mean(sum) / batch_size\n",
    "        for j in range(batch_size):\n",
    "            mini_batch[j][i] = (mini_batch[j][i] - mean)  / torch.sqrt(variance + epsilon)\n",
    "        sum = 0\n",
    "    return mini_batch\n",
    "\n",
    "def prepare_and_init_Net_with_batch_norm(eps):\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, device):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 11)\n",
    "            self.conv2 = nn.Conv2d(6, 12, 9)\n",
    "            self.conv3 = nn.Conv2d(12, 24, 7)\n",
    "            self.conv4 = nn.Conv2d(24, 30, 6)\n",
    "            self.pool2 = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(30 * 10 * 10, 600)\n",
    "            self.fc1_bn = nn.BatchNorm1d(600)\n",
    "            self.fc3 = nn.Linear(600, 28)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool2(F.relu(mini_batch_normalization(self.conv1(x), eps)))\n",
    "            x = self.pool2(F.relu(mini_batch_normalization(self.conv2(x), eps)))\n",
    "            x = self.pool2(F.relu(mini_batch_normalization(self.conv3(x), eps)))\n",
    "            x = self.pool2(F.relu(mini_batch_normalization(self.conv4(x), eps)))\n",
    "            x = x.view(-1, 30 * 10 * 10)\n",
    "            x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "    net = Net(device='cuda:0')\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def prepare_and_init_Net_without_batch_norm():\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, device):\n",
    "            super(Net, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(3, 6, 11)\n",
    "            self.conv2 = nn.Conv2d(6, 12, 9)\n",
    "            self.conv3 = nn.Conv2d(12, 24, 7)\n",
    "            self.conv4 = nn.Conv2d(24, 30, 6)\n",
    "            self.pool2 = nn.MaxPool2d(2, 2)\n",
    "            self.fc1 = nn.Linear(30 * 10 * 10, 600)\n",
    "            self.fc3 = nn.Linear(600, 28)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool2(F.relu(self.conv1(x)))\n",
    "            x = self.pool2(F.relu(self.conv2(x)))\n",
    "            x = self.pool2(F.relu(self.conv3(x)))\n",
    "            x = self.pool2(F.relu(self.conv4(x)))\n",
    "            x = x.view(-1, 30 * 10 * 10)\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "\n",
    "    net = Net(device='cuda:0')\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def crit_and_opt(learning_rate, net):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    return criterion, optimizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def cuda_init():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return device\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def learn(device, trainloader, optimizer, criterion, net):\n",
    "    running_loss_for_optimizer = 0.0\n",
    "    running_loss = 0.0\n",
    "    loss_for_optimizer = 1.0\n",
    "    learning_rate = 0.001\n",
    "    for epoch in range(15):  # loop over the dataset multiple times\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_loss_for_optimizer += loss.item()\n",
    "            if i % 1000 == 999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 1000))\n",
    "                running_loss = 0.0\n",
    "        print(\"running loss at end of epoch: \", running_loss_for_optimizer/len(trainloader))\n",
    "        # if the loss is low enough, we decrease the learning rate\n",
    "        if(running_loss_for_optimizer/len(trainloader) < loss_for_optimizer):\n",
    "            learning_rate /= 2\n",
    "            loss_for_optimizer /= 2\n",
    "            criterion, optimizer = crit_and_opt(learning_rate)\n",
    "            print( \"devaluating optimizer, current value: \", loss_for_optimizer)\n",
    "        running_loss_for_optimizer = 0.0\n",
    "        running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def conf_matrix(net, testloader):\n",
    "    device = cuda_init()\n",
    "    conf_mat = torch.zeros(28, 28)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            for i in range(images.shape[0]):\n",
    "                label = labels[i]\n",
    "                predict = predicted[i]\n",
    "                conf_mat[label.item()][predict.item()] +=1\n",
    "    return conf_mat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "net = prepare_and_init_Net_with_batch_norm(10**(-15))\n",
    "PATH = './actors_net_batch_norm.pth'\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "trainloader, testloader, classes = prepare_data()\n",
    "tmp = conf_matrix(net, testloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7439)\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(28):\n",
    "    sum += tmp[i][i]/99\n",
    "print(sum/28)\n",
    "# print(tmp)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}